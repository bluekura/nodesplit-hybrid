{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import leidenalg\n",
    "import igraph as ig\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "from clusim.clustering import Clustering, print_clustering\n",
    "import clusim.sim as sim\n",
    "import gc\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import psutil\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge leidenalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRawNodesplitNetwork_BC_CC(raw_edgelist): # edglist format: (from, to)\n",
    "    numlayer = 3\n",
    "    res_edgelist = []\n",
    "    sumweight_per_layer = defaultdict(lambda: [0] * numlayer)\n",
    "    # index 0: Clustering-Clustering weight\n",
    "    # index 1: Clus\n",
    "    \n",
    "    # mutiply the node index by 10 and add the last digit to distinguish the type of node\n",
    "    # last digit information: \n",
    "    # a node -> clustring(0), citing(1), cited nodes(2)\n",
    "    # basic rules: \n",
    "    # 1) citing node cites clustering node (*1->*0) (CC)\n",
    "    # 2) clustring node cites cited node (*0->*2) (BC)\n",
    "    # 3~9 Reserved for now (candidates: keyword, affiliation, and etc...)\n",
    "    # retunning edge node order: (clustering node, other layer distinguished with a last digit)\n",
    "    for edge in raw_edgelist:\n",
    "        citing_node = edge[0] * 10 + 1\n",
    "        clustering_node_cited = edge[1] * 10       \n",
    "        cited_node = edge[1] * 10 + 2\n",
    "        clustering_node_citing = edge[0] * 10\n",
    "        \n",
    "        sumweight_per_layer[clustering_node_cited][1] += 1\n",
    "        sumweight_per_layer[clustering_node_citing][2] += 1\n",
    "\n",
    "        res_edgelist.append((clustering_node_cited, citing_node))\n",
    "        res_edgelist.append((clustering_node_citing, cited_node))\n",
    "        \n",
    "    return res_edgelist, sumweight_per_layer\n",
    "\n",
    "def normNodesplitNetwork_BC_CC(raw_edgelist, r_layerslist = [0, 0.5, 0.5]): # edglist format: (from, to)\n",
    "    res_edgelist, strengthdict = genRawNodesplitNetwork_BC_CC(raw_edgelist)\n",
    "    res_weighed_edgelist = []\n",
    "    for edge in res_edgelist:\n",
    "        target_layer = edge[1] % 10\n",
    "        weight = 1 / strengthdict[edge[0]][target_layer] * r_layerslist[target_layer]\n",
    "        #if(edge[0] % 10 != 0):\n",
    "        #    print(\"error!\")\n",
    "        if(weight == 0):\n",
    "            continue\n",
    "        res_weighed_edgelist.append((edge[0], edge[1], weight))        \n",
    "    return res_weighed_edgelist\n",
    "        \n",
    "def genRawNodesplitNetwork_BC_CC_DCT1(raw_edgelist): # edglist format: (from, to)\n",
    "    numlayer = 3\n",
    "    res_edgelist = []\n",
    "    sumweight_per_layer = defaultdict(lambda: [0] * numlayer)\n",
    "    \n",
    "    # mutiply the node index by 10 and add the last digit to distinguish the type of node\n",
    "    # last digit information: \n",
    "    # a node -> clustring(0), citing(1), cited nodes(2)\n",
    "    # basic rules: \n",
    "    # 1) citing node cites clustering node (*1->*0) (CC)\n",
    "    # 2) clustring node cites cited node (*0->*2) (BC)\n",
    "    # 3) clustering node cites clustring node (DC)\n",
    "    # 3~9 Reserved for now (candidates: keyword, affiliation, and etc...)\n",
    "    # retunning edge node order: (clustering node, other layer distinguished with a last digit)\n",
    "    \n",
    "    for edge in raw_edgelist:\n",
    "        citing_node = edge[0] * 10 + 1\n",
    "        clustering_node_cited= edge[1] * 10\n",
    "        cited_node = edge[1] * 10 + 2\n",
    "        clustering_node_citing = edge[0] * 10\n",
    "\n",
    "        sumweight_per_layer[clustering_node_cited][1] += 1\n",
    "        sumweight_per_layer[clustering_node_citing][2] += 1\n",
    "        sumweight_per_layer[clustering_node_cited][0] += 1\n",
    "        sumweight_per_layer[clustering_node_citing][0] += 1\n",
    "        \n",
    "        res_edgelist.append((clustering_node_cited, citing_node))\n",
    "        res_edgelist.append((clustering_node_citing, cited_node))        \n",
    "        res_edgelist.append((clustering_node_citing, clustering_node_cited))\n",
    "    return res_edgelist, sumweight_per_layer\n",
    "\n",
    "def normNodesplitNetwork_BC_CC_DCT1(raw_edgelist, r_layerslist = [1/3, 1/3, 1/3]): # edglist format: (from, to)\n",
    "    res_edgelist, strengthdict = genRawNodesplitNetwork_BC_CC_DCT1(raw_edgelist)\n",
    "    res_weighed_edgelist = []\n",
    "    for edge in res_edgelist:\n",
    "        target_layer = edge[1] % 10\n",
    "        weight = 1 / strengthdict[edge[0]][target_layer] * r_layerslist[target_layer]\n",
    "        res_weighed_edgelist.append((edge[0], edge[1], weight))\n",
    "        if(edge[0] % 10 != 0):\n",
    "            print(\"error!\")\n",
    "        if(target_layer == 0):\n",
    "            weight = 1 / strengthdict[edge[1]][target_layer] * r_layerslist[target_layer]\n",
    "        else:\n",
    "            pass\n",
    "        res_weighed_edgelist.append((edge[1], edge[0], weight))\n",
    "    return res_weighed_edgelist # One should be note that it returns Directed Weight Network unlike others\n",
    "\n",
    "def genRawNodesplitNetwork_BC_CC_DCT2(raw_edgelist): # edglist format: (from, to)\n",
    "    numlayer = 4\n",
    "    res_edgelist = []\n",
    "    sumweight_per_layer = defaultdict(lambda: [0] * numlayer)\n",
    "       \n",
    "    # mutiply the node index by 10 and add the last digit to distinguish the type of node\n",
    "    # last digit information: \n",
    "    # a node -> clustring(0), citing(1), cited nodes(2)\n",
    "    # basic rules: \n",
    "    # 1) citing node cites clustering node (*1->*0) (CC)\n",
    "    # 2) clustring node cites cited node (*0->*2) (BC)\n",
    "    # 3) clustering node cites clustring node via pseudo node (*0->*3->*0)(DC)\n",
    "    #    here, pseudo node represent direct citation between them\n",
    "    # 4~9 Reserved for now (candidates: keyword, affiliation, and etc...)\n",
    "    current_dc_index = 0\n",
    "    \n",
    "    for edge in raw_edgelist:\n",
    "        citing_node = edge[0] * 10 + 1\n",
    "        clustering_node_cited= edge[1] * 10\n",
    "        cited_node = edge[1] * 10 + 2\n",
    "        clustering_node_citing = edge[0] * 10\n",
    "        pseudo_dc_node = current_dc_index * 10 + 3\n",
    "        current_dc_index += 1\n",
    "\n",
    "        res_edgelist.append((clustering_node_cited, citing_node))\n",
    "        res_edgelist.append((clustering_node_citing, cited_node))        \n",
    "        res_edgelist.append((clustering_node_citing, pseudo_dc_node))\n",
    "        res_edgelist.append((clustering_node_cited, pseudo_dc_node))\n",
    "        \n",
    "        sumweight_per_layer[clustering_node_cited][1] += 1\n",
    "        sumweight_per_layer[clustering_node_citing][2] += 1\n",
    "        sumweight_per_layer[clustering_node_cited][3] += 1\n",
    "        sumweight_per_layer[clustering_node_citing][3] += 1\n",
    "        \n",
    "    return res_edgelist, sumweight_per_layer\n",
    "\n",
    "def normNodesplitNetwork_BC_CC_DCT2(raw_edgelist, r_layerslist = [0, 1/3, 1/3, 1/3]): # edglist format: (from, to)\n",
    "    res_edgelist, strengthdict = genRawNodesplitNetwork_BC_CC_DCT2(raw_edgelist)\n",
    "    res_weighed_edgelist = []\n",
    "    for edge in res_edgelist:\n",
    "        target_layer = edge[1] % 10\n",
    "        weight = 1 / strengthdict[edge[0]][target_layer] * r_layerslist[target_layer]\n",
    "        res_weighed_edgelist.append((edge[0], edge[1], weight))\n",
    "    return res_weighed_edgelist\n",
    "\n",
    "def calc_granularity_clusters(cluster_list):\n",
    "    # cluster list: list idx = cluster idx\n",
    "    # list[cluster idx]: list of node indexes for a certain cluster\n",
    "    cluster_count = len(cluster_list)\n",
    "    total_count = sum([len(x) for x in cluster_list])\n",
    "    gran_denom = sum([len(x)**2 for x in cluster_list])\n",
    "    gran1 = total_count / gran_denom\n",
    "    #gran2 = len(cluster_count) / gran_denom\n",
    "    return gran1\n",
    "\n",
    "def get_filelength(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "def f_out_clusters(clusterdict, filename):\n",
    "    f_out = open(filename, \"w\")\n",
    "    for k, v in clusterdict.items():\n",
    "        f_out.write(str(k) + \"\\t\" + str(v) + \"\\n\")\n",
    "    f_out.close()\n",
    "       \n",
    "def get_cluster_score(ig_network, header, fosname, r_layers, res):\n",
    "    part_now_leidenRB = leidenalg.find_partition(ig_network, leidenalg.RBConfigurationVertexPartition, resolution_parameter=res, weights =\"weight\")\n",
    "    cur_elm2clu_dict = {}\n",
    "    for idx, cluster in enumerate(part_now_leidenRB):\n",
    "        for node in cluster:\n",
    "            cur_node = part_now_leidenRB.graph.vs[node][\"name\"]\n",
    "            if(cur_node % 10 == 0):\n",
    "                cur_elm2clu_dict[int(cur_node/10)] = idx\n",
    "    c1_name = set(cur_elm2clu_dict)\n",
    "    c2_name = set(paperfielddict)\n",
    "    intersectionset = c1_name.intersection(c2_name)\n",
    "    del(c1_name)\n",
    "    del(c2_name)\n",
    "    dict1 = {}\n",
    "    dict2 = {}\n",
    "    for idx_tmp, val in enumerate(intersectionset):\n",
    "        dict1[idx_tmp] = paperfielddict[val]\n",
    "        dict2[idx_tmp] = [cur_elm2clu_dict[val]]\n",
    "    c1 = Clustering(elm2clu_dict = dict1)\n",
    "    c2 = Clustering(elm2clu_dict = dict2)\n",
    "    outclu_fname = \"./Cluster_out/\" + header + \"_\" + fosname + \"_r_\" + \"_\".join([format(x, \".2f\") for x in r_layers]) + \"_\" + format(res, \".2f\") + \".clu\"\n",
    "    f_out_clusters(cur_elm2clu_dict, outclu_fname)\n",
    "    granularity = calc_granularity_clusters(part_now_leidenRB)\n",
    "    nmi_sim = sim.nmi(c1, c2)\n",
    "    return([header, fosname, r_layers, res, granularity, nmi_sim])\n",
    "\n",
    "def get_cluster_score_nofileout(ig_network, header, fosname, r_layers, res):\n",
    "    part_now_leidenRB = leidenalg.find_partition(ig_network, leidenalg.RBConfigurationVertexPartition, resolution_parameter=res, weights =\"weight\")\n",
    "    cur_elm2clu_dict = {}\n",
    "    for idx, cluster in enumerate(part_now_leidenRB):\n",
    "        for node in cluster:\n",
    "            cur_node = part_now_leidenRB.graph.vs[node][\"name\"]\n",
    "            if(cur_node % 10 == 0):\n",
    "                cur_elm2clu_dict[int(cur_node/10)] = idx\n",
    "    c1_name = set(cur_elm2clu_dict)\n",
    "    c2_name = set(paperfielddict)\n",
    "    intersectionset = c1_name.intersection(c2_name)\n",
    "    del(c1_name)\n",
    "    del(c2_name)\n",
    "    dict1 = {}\n",
    "    dict2 = {}\n",
    "    for idx_tmp, val in enumerate(intersectionset):\n",
    "        dict1[idx_tmp] = paperfielddict[val]\n",
    "        dict2[idx_tmp] = [cur_elm2clu_dict[val]]\n",
    "    c1 = Clustering(elm2clu_dict = dict1)\n",
    "    c2 = Clustering(elm2clu_dict = dict2)\n",
    "    granularity = calc_granularity_clusters(part_now_leidenRB)\n",
    "    nmi_sim = sim.nmi(c1, c2)\n",
    "    return([header, fosname, r_layers, res, granularity, nmi_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FieldReferences = pd.read_csv(\"./Processed_data/MAG_ALLReferenceL0FieldMerged.tsv\", sep=\"\\t\", )\n",
    "#FieldReferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOS_datafile = \"./MAG_dataset/advanced/FieldsOfStudy.txt\"\n",
    "df_fosinfo = pd.read_csv(FOS_datafile, sep=\"\\t\", header=None, usecols=[0, 3, 5, 6], quoting=csv.QUOTE_NONE)\n",
    "df_fosinfo.columns = [\"FieldofStudyId\", \"FosName\", \"FosLevel\", \"PaperCount\"]\n",
    "L0_FOSID_List = df_fosinfo[df_fosinfo[\"FosLevel\"] == 0][\"FieldofStudyId\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fosinfo[df_fosinfo[\"FosLevel\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fos_l0_namedict = df_fosinfo[df_fosinfo[\"FosLevel\"] == 0].set_index(\"FieldofStudyId\")[\"FosName\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_mag_l2_field = \"./fastnvme01//MAG_PaperFieldL2_MAX.txt\"\n",
    "paperfielddict = defaultdict(list)\n",
    "with open(input_file_mag_l2_field, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    next(reader)\n",
    "    for row in reader:  \n",
    "        paperfielddict[int(row[0])].append(int(row[3]))\n",
    "print(len(paperfielddict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetFOSList = L0_FOSID_List\n",
    "reslist = [0.2*x for x in range(1, 101)]\n",
    "result_list = []\n",
    "count_clustering_nodes = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_reference_with_l0 = \"./fastnvme01//MAG_ALLReferenceL0FieldMerged.tsv\"\n",
    "field_edge_list_dict = defaultdict(list)\n",
    "with open(input_file_reference_with_l0, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    next(reader)\n",
    "    #for row in tqdm(reader, total=get_filelength(input_file_reference_with_l0)): # for a new file\n",
    "    for row in tqdm(reader, total=956198971): # Hard coded to improve the speed\n",
    "        if(row[1] == row[3]):\n",
    "            field_edge_list_dict[int(row[1])].append((int(row[0]), int(row[2])))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fos in sorted(field_edge_list_dict, key=lambda k: len(field_edge_list_dict[k]), reverse=False):\n",
    "    print(fos_l0_namedict[fos], fos, len(field_edge_list_dict[fos]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetFOSList = [144024400, 41008148, 162324750, 192562407, 33923547, 121332964]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_process = 10\n",
    "                \n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-BC-CC-Hybrid\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [0, 1/2, 1/2]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=False, weights=True)\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()    \n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-CC\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS]   \n",
    "    r_layers = [0, 1, 0]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=False, weights=True)\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()    \n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers)    \n",
    "    result_list += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()\n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-BC\"   \n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]\n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS]\n",
    "    r_layers = [0, 0, 1]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=False, weights=True)\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()    \n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)           \n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))     \n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_process = 10\n",
    "                \n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-BC-CC-Hybrid\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [0, 1/10, 9/10]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=False, weights=True)\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()    \n",
    "\n",
    "no_process = 10\n",
    "                \n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-BC-CC-Hybrid\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [0, 9/10, 1/10]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=False, weights=True)\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len (result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l2_sim_BC_CC = pd.DataFrame(result_list)\n",
    "df_l2_sim_BC_CC.columns = [\"NetworkType\", \"L0FOS\", \"LayerRatio\", \"ResParm\", \"Granularity\", \"L2NMI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if you want to save the sim file\n",
    "#df_l2_sim_BC_CC.to_csv(\"./MAG_L2_Similarity/20200907_BC-CC.tsv\", sep = \"\\t\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_FOS_LIST = df_l2_sim_BC_CC[\"L0FOS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for FOS in DF_FOS_LIST:\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    df_l2_sim_BC_CC[(df_l2_sim_BC_CC[\"NetworkType\"] == \"NS-BC-CC-Hybrid\")\n",
    "                    & (df_l2_sim_BC_CC[\"LayerRatio\"].map(tuple).isin([(0,0.5, 0.5)]))\n",
    "                    & (df_l2_sim_BC_CC[\"L0FOS\"] == FOS)].set_index(\"Granularity\")[\"L2NMI\"].plot()\n",
    "    df_l2_sim_BC_CC[(df_l2_sim_BC_CC[\"NetworkType\"] == \"NS-BC-CC-Hybrid\")\n",
    "                    & (df_l2_sim_BC_CC[\"LayerRatio\"].map(tuple).isin([(0,0.1, 0.9)]))\n",
    "                    & (df_l2_sim_BC_CC[\"L0FOS\"] == FOS)].set_index(\"Granularity\")[\"L2NMI\"].plot()\n",
    "    df_l2_sim_BC_CC[(df_l2_sim_BC_CC[\"NetworkType\"] == \"NS-BC-CC-Hybrid\")\n",
    "                    & (df_l2_sim_BC_CC[\"LayerRatio\"].map(tuple).isin([(0,0.9, 0.1)]))\n",
    "                    & (df_l2_sim_BC_CC[\"L0FOS\"] == FOS)].set_index(\"Granularity\")[\"L2NMI\"].plot()        \n",
    "    df_l2_sim_BC_CC[(df_l2_sim_BC_CC[\"NetworkType\"] == \"NS-BC\")\n",
    "                    & (df_l2_sim_BC_CC[\"LayerRatio\"].map(tuple).isin([(0, 0, 1)]))\n",
    "                    & (df_l2_sim_BC_CC[\"L0FOS\"] == FOS)].set_index(\"Granularity\")[\"L2NMI\"].plot()\n",
    "    df_l2_sim_BC_CC[(df_l2_sim_BC_CC[\"NetworkType\"] == \"NS-CC\")\n",
    "                    & (df_l2_sim_BC_CC[\"LayerRatio\"].map(tuple).isin([(0, 1, 0)]))\n",
    "                    & (df_l2_sim_BC_CC[\"L0FOS\"] == FOS)].set_index(\"Granularity\")[\"L2NMI\"].plot()\n",
    "    plt.title(FOS)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l2_sim_BC_CC[\"LayerRatio\"].map(tuple).isin([(0,0.5, 0.5)]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetFOSList = [144024400, 41008148, 162324750, 192562407, 33923547]#, 121332964]\n",
    "#TargetFOSList = [121332964]\n",
    "result_list2 = []\n",
    "no_process = 6\n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-BC-CC-DC-Hybrid-T2\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [0, 1/3, 1/3, 1/3]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT2(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=False, weights=True)\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list2 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetFOSList = [144024400, 41008148, 162324750, 192562407, 33923547]#, 121332964]\n",
    "result_list3 = []\n",
    "\n",
    "no_process = 6\n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-BC-CC-DC-Hybrid-T1\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [1/3, 1/3, 1/3]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT1(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=True, weights=True) # T1 BC-CC-DC hybrid should be treated as directed weighted network\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list3 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()\n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-BC-CC-DC-Hybrid-T1\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [1/10, 9/20, 9/20]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT1(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=True, weights=True) # T1 BC-CC-DC hybrid should be treated as directed weighted network\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list3 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l2_sim_BC_CC3 = pd.DataFrame(result_list3)\n",
    "df_l2_sim_BC_CC3.columns = [\"NetworkType\", \"L0FOS\", \"LayerRatio\", \"ResParm\", \"Granularity\", \"L2NMI\"]\n",
    "df_l2_sim_BC_CC3.to_csv(\"./MAG_L2_Similarity/20200923_BC_CC_DC_T1_1.tsv\", sep = \"\\t\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Physics Separately\n",
    "# TargetFOSList = [144024400, 41008148, 162324750, 192562407, 33923547, 121332964]\n",
    "TargetFOSList = [121332964]\n",
    "result_list4 = []\n",
    "no_process = 4\n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-BC-CC-DC-Hybrid-T2\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [0, 1/3, 1/3, 1/3]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT2(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=False, weights=True)\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list4 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l2_sim_BC_CC4 = pd.DataFrame(result_list4)\n",
    "df_l2_sim_BC_CC4.columns = [\"NetworkType\", \"L0FOS\", \"LayerRatio\", \"ResParm\", \"Granularity\", \"L2NMI\"]\n",
    "df_l2_sim_BC_CC4.to_csv(\"./MAG_L2_Similarity/20200923_BC_CC_DC_T2_2.tsv\", sep = \"\\t\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetFOSList = [121332964]\n",
    "result_list5 = []\n",
    "no_process = 4\n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-BC-CC-DC-Hybrid-T1\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [1/3, 1/3, 1/3]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT1(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=True, weights=True) # T1 BC-CC-DC hybrid should be treated as directed weighted network\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list5 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()\n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"NS-BC-CC-DC-Hybrid-T1\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [1/10, 9/20, 9/20]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT1(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=True, weights=True) # T1 BC-CC-DC hybrid should be treated as directed weighted network\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list5 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l2_sim_BC_CC5 = pd.DataFrame(result_list5)\n",
    "df_l2_sim_BC_CC5.columns = [\"NetworkType\", \"L0FOS\", \"LayerRatio\", \"ResParm\", \"Granularity\", \"L2NMI\"]\n",
    "df_l2_sim_BC_CC5.to_csv(\"./MAG_L2_Similarity/20200923_BC_CC_DC_T1_2.tsv\", sep = \"\\t\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Physics Separately\n",
    "TargetFOSList = [144024400, 41008148, 162324750, 192562407, 33923547]#, 121332964]\n",
    "#TargetFOSList = [121332964]\n",
    "result_list6 = []\n",
    "no_process = 6\n",
    "   \n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"DC-T1\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [1, 0, 0]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT1(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=True, weights=True) # T1 BC-CC-DC hybrid should be treated as directed weighted network\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list6 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()\n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"DC-T2\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [0, 0, 0, 1]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT2(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=False, weights=True)\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list6 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l2_sim_BC_CC6 = pd.DataFrame(result_list6)\n",
    "df_l2_sim_BC_CC6.columns = [\"NetworkType\", \"L0FOS\", \"LayerRatio\", \"ResParm\", \"Granularity\", \"L2NMI\"]\n",
    "df_l2_sim_BC_CC6.to_csv(\"./MAG_L2_Similarity/202001001_DC_1.tsv\", sep = \"\\t\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Physics Separately\n",
    "# TargetFOSList = [144024400, 41008148, 162324750, 192562407, 33923547, 121332964]\n",
    "TargetFOSList = [121332964]\n",
    "result_list7 = []\n",
    "no_process = 4\n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"DC-T2\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [0, 0, 0, 1]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT2(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=False, weights=True)\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list7 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()\n",
    "    \n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    typename =  \"DC-T1\"\n",
    "    FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "    #lst_citation_subset = FieldReferences[(FieldReferences[\"FOSCiting\"] == TargetFOS) & (FieldReferences[\"FOSCited\"] == TargetFOS)][[\"CitingId\", \"CitedId\"]].values.tolist()\n",
    "    lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "    r_layers = [1, 0, 0]\n",
    "    nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT1(lst_citation_subset, r_layers)\n",
    "    G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=True, weights=True) # T1 BC-CC-DC hybrid should be treated as directed weighted network\n",
    "    G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "    del(lst_citation_subset)\n",
    "    del(nodesplitBCCC)\n",
    "    gc.collect()\n",
    "    for node in G_NS_HB_BC_CC.vs:\n",
    "        if(node[\"name\"] % 10 == 0):\n",
    "            count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "    pool = Pool(processes=no_process)\n",
    "    func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "    result_list5 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "    pool.close()         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l2_sim_BC_CC7 = pd.DataFrame(result_list7)\n",
    "df_l2_sim_BC_CC7.columns = [\"NetworkType\", \"L0FOS\", \"LayerRatio\", \"ResParm\", \"Granularity\", \"L2NMI\"]\n",
    "df_l2_sim_BC_CC7.to_csv(\"./MAG_L2_Similarity/202001001_DC_2.tsv\", sep = \"\\t\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 왜 DC T2가 성능이 좋을까? DC-T2만으로도 성능이 좋을까? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Run Physics Separately\n",
    "TargetFOSList = [144024400, 41008148, 162324750, 192562407, 33923547 121332964]\n",
    "#TargetFOSList = [121332964]\n",
    "result_list8 = []\n",
    "no_process = 4\n",
    "\n",
    "r_dc_list = [0.9, 0.5, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "for TargetFOS in tqdm(TargetFOSList):\n",
    "    for r_dc in r_dc_list:\n",
    "        typename =  \"NS-BC-CC-DC-Hybrid-T1\"\n",
    "        FOSNAME = fos_l0_namedict[TargetFOS]   \n",
    "        lst_citation_subset = field_edge_list_dict[TargetFOS] # Do not forget. = operator of list is just copying a address pointer. \n",
    "        r_ccbc = (1-r_dc)/2\n",
    "        r_layers = [r_dc, r_ccbc, r_ccbc]\n",
    "        nodesplitBCCC = normNodesplitNetwork_BC_CC_DCT1(lst_citation_subset, r_layers)\n",
    "        G_NS_HB_BC_CC = ig.Graph.TupleList(nodesplitBCCC, directed=True, weights=True) # T1 BC-CC-DC hybrid should be treated as directed weighted network\n",
    "        G_NS_HB_BC_CC = G_NS_HB_BC_CC.components().giant()\n",
    "        del(lst_citation_subset)\n",
    "        del(nodesplitBCCC)\n",
    "        gc.collect()\n",
    "        for node in G_NS_HB_BC_CC.vs:\n",
    "            if(node[\"name\"] % 10 == 0):\n",
    "                count_clustering_nodes[(TargetFOS, typename)] += 1\n",
    "        pool = Pool(processes=no_process)\n",
    "        func = partial(get_cluster_score, G_NS_HB_BC_CC, typename, FOSNAME, r_layers) \n",
    "        result_list8 += list(tqdm(pool.imap(func, reslist), total=len(reslist), desc = FOSNAME))\n",
    "        pool.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l2_sim_BC_CC8 = pd.DataFrame(result_list8)\n",
    "df_l2_sim_BC_CC8.columns = [\"NetworkType\", \"L0FOS\", \"LayerRatio\", \"ResParm\", \"Granularity\", \"L2NMI\"]\n",
    "df_l2_sim_BC_CC8.to_csv(\"./MAG_L2_Similarity/202001001_DC_2.tsv\", sep = \"\\t\", index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
