{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import csv\n",
    "from clusim.clustering import Clustering, print_clustering\n",
    "import clusim.sim as sim\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nmi_subset(target_dict, ref_dict):\n",
    "    c1_name = set(target_dict)\n",
    "    c2_name = set(ref_dict)\n",
    "    intersectionset = c1_name.intersection(c2_name)\n",
    "    del(c1_name)\n",
    "    del(c2_name)\n",
    "    dict1 = {}\n",
    "    dict2 = {}\n",
    "    for idx_tmp, val in enumerate(intersectionset):\n",
    "        dict1[idx_tmp] = [target_dict[val]]\n",
    "        dict2[idx_tmp] = [ref_dict[val]]\n",
    "    c1 = Clustering(elm2clu_dict = dict1)\n",
    "    c2 = Clustering(elm2clu_dict = dict2)\n",
    "    nmi_sim = sim.nmi(c1, c2)\n",
    "    return nmi_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOS_datafile = \"./MAG_dataset/advanced/FieldsOfStudy.txt\"\n",
    "df_fosinfo = pd.read_csv(FOS_datafile, sep=\"\\t\", header=None, usecols=[0, 3, 5, 6], quoting=csv.QUOTE_NONE)\n",
    "df_fosinfo.columns = [\"FieldofStudyId\", \"FosName\", \"FosLevel\", \"PaperCount\"]\n",
    "fos_l0_namedict = df_fosinfo[df_fosinfo[\"FosLevel\"] == 0].set_index(\"FosName\")[\"FieldofStudyId\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_mag_l2_field = \"./fastnvme01//MAG_PaperFieldL2_MAX.txt\"\n",
    "paperfielddict = defaultdict(int)\n",
    "with open(input_file_mag_l2_field, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    next(reader)\n",
    "    for row in reader:  \n",
    "        paperfielddict[int(row[0])] = int(row[3])\n",
    "print(len(paperfielddict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infield = pd.read_csv(\"./Processed_data/MAG_L0CitationCounts.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infield[\"IF_PCT\"] = df_infield.groupby(\"L0Field\")[\"InFieldCitationCounts\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"./Processed_data/MAG_CitationCounts.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"ALL_PCT\"] = df_all[\"CitationCounts\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_infield[[\"PaperId\", \"L0Field\"]].merge(df_all, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_granularity_cludict(cluster_dict):\n",
    "    # cluster list: list idx = cluster idx\n",
    "    # list[cluster idx]: list of node indexes for a certain cluster\n",
    "    cluster_count = len(set(cluster_dict.values()))\n",
    "    total_count = len(cluster_dict)\n",
    "    gran_denom = sum([x**2 for x in Counter(cluster_dict.values()).values()])\n",
    "    gran1 = total_count / gran_denom\n",
    "    #gran2 = len(cluster_count) / gran_denom\n",
    "    return gran1\n",
    "\n",
    "def get_params_from_filename(fname):\n",
    "    subname = fname.split(\"/\")[3]\n",
    "    net_type = subname.split(\"_\", 1)[0]\n",
    "    res = subname.rsplit(\"_\", 1)[1].rsplit(\".\", 1)[0]\n",
    "    temp = subname.split(\"_\", 3)\n",
    "    if(temp[2][0]==\"r\"):\n",
    "        fieldname = temp[1]\n",
    "        r_layer = tuple(temp[3].rsplit(\"_\", 1)[0].split(\"_\"))\n",
    "    else:\n",
    "        fieldname = temp[1]+\" \"+temp[2]\n",
    "        r_layer = tuple(temp[3].split(\"_\", 1)[1].rsplit(\"_\", 1)[0].split(\"_\"))\n",
    "    return [net_type, fieldname, r_layer, res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmi_calculate_quantiles(fname):\n",
    "    now_quantile_list = []\n",
    "    param_list = get_params_from_filename(fname)\n",
    "    clusters = pd.read_csv(fname, sep=\"\\t\", header=None, names=[\"PaperId\", \"ClusterNum\"])\n",
    "    bound = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "    L0FOSID = fos_l0_namedict[param_list[1]]\n",
    "    for i in range(len(bound)-1):\n",
    "        lb = bound[i]\n",
    "        ub = bound[i+1]\n",
    "        paper_sublist = df_infield[(df_infield[\"L0Field\"]==L0FOSID) & (df_infield[\"IF_PCT\"] >= lb)  & (df_infield[\"IF_PCT\"] < ub)].sort_values(\"IF_PCT\")[\"PaperId\"].to_list()\n",
    "        subclusters = clusters[clusters[\"PaperId\"].isin(paper_sublist)]\n",
    "        clusterdict = subclusters.set_index(\"PaperId\")[\"ClusterNum\"].to_dict()\n",
    "        if(len(subclusters) == 0):\n",
    "            continue\n",
    "        nmi_val = get_nmi_subset(clusterdict, paperfielddict)\n",
    "        subgran = calc_granularity_cludict(clusterdict)\n",
    "        res = param_list + [lb, ub, nmi_val, subgran, nmi_val/subgran]\n",
    "        now_quantile_list.append(res)\n",
    "    return now_quantile_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_process = 32\n",
    "filenames = sorted(glob.glob(\"./fastnvme01/Cluster_out/*.clu\"))\n",
    "quartile_result = []\n",
    "quartile_result.append([\"net_type\", \"field_name\", \"r_layer\", \"res\", \"pct_lb\", \"pct_ub\", \"nmi\", \"granularity\", \"nmi_per_gran\"])\n",
    "\n",
    "pool = Pool(processes=no_process)\n",
    "sub_quartile_result = list(tqdm(pool.imap(nmi_calculate_quantiles, filenames), total=len(filenames), desc = \"QUANTILE\"))\n",
    "pool.close()\n",
    "quartile_result += list(itertools.chain(*sub_quartile_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_df = pd.DataFrame(quartile_result[1:], columns=quartile_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_df.to_csv(\"./MAG_L2_Similarity/20201028_NMI_BY_CITATION_INFILED_QUANTILE.tsv\", index=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmi_calculate_quantiles_all(fname):\n",
    "    now_quantile_list = []\n",
    "    param_list = get_params_from_filename(fname)\n",
    "    clusters = pd.read_csv(fname, sep=\"\\t\", header=None, names=[\"PaperId\", \"ClusterNum\"])\n",
    "    bound = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "    L0FOSID = fos_l0_namedict[param_list[1]]    \n",
    "    for i in range(len(bound)-1):\n",
    "        lb = bound[i]\n",
    "        ub = bound[i+1]\n",
    "        paper_sublist = df_all[(df_all[\"L0Field\"]==L0FOSID) & (df_all[\"ALL_PCT\"] >= lb)  & (df_all[\"ALL_PCT\"] < ub)].sort_values(\"ALL_PCT\")[\"PaperId\"].to_list()\n",
    "        subclusters = clusters[clusters[\"PaperId\"].isin(paper_sublist)]\n",
    "        clusterdict = subclusters.set_index(\"PaperId\")[\"ClusterNum\"].to_dict()\n",
    "        if(len(subclusters) == 0):\n",
    "            continue\n",
    "        nmi_val = get_nmi_subset(clusterdict, paperfielddict)\n",
    "        subgran = calc_granularity_cludict(clusterdict)\n",
    "        res = param_list + [lb, ub, nmi_val, subgran, nmi_val/subgran]\n",
    "        now_quantile_list.append(res)\n",
    "    return now_quantile_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_process = 32\n",
    "filenames = sorted(glob.glob(\"./fastnvme01/Cluster_out/*.clu\"))\n",
    "all_quartile_result = []\n",
    "all_quartile_result.append([\"net_type\", \"field_name\", \"r_layer\", \"res\", \"pct_lb\", \"pct_ub\", \"nmi\", \"granularity\", \"nmi_per_gran\"])\n",
    "\n",
    "pool = Pool(processes=no_process)\n",
    "sub_all_quartile_result = list(tqdm(pool.imap(nmi_calculate_quantiles_all, filenames), total=len(filenames), desc = \"QUANTILE\"))\n",
    "pool.close()\n",
    "all_quartile_result += list(itertools.chain(*sub_all_quartile_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quantile_df = pd.DataFrame(all_quartile_result[1:], columns=all_quartile_result[0])\n",
    "all_quantile_df.to_csv(\"./MAG_L2_Similarity/20201028_NMI_BY_CITATION_ALL_QUANTILE.tsv\", index=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmi_calculate_citation_count(fname):\n",
    "    now_count_list = []\n",
    "    param_list = get_params_from_filename(fname)\n",
    "    clusters = pd.read_csv(fname, sep=\"\\t\", header=None, names=[\"PaperId\", \"ClusterNum\"])\n",
    "    L0FOSID = fos_l0_namedict[param_list[1]]\n",
    "    max_len = int(math.log(df_infield[(df_infield[\"L0Field\"]==L0FOSID)][\"InFieldCitationCounts\"].max(), multip)) + 1\n",
    "    bound = [multip ** i for i in range(max_len)]   \n",
    "    for i in range(len(bound)-1):\n",
    "        lb = bound[i]\n",
    "        ub = bound[i+1]\n",
    "        paper_sublist = df_infield[(df_infield[\"L0Field\"]==L0FOSID) & (df_infield[\"InFieldCitationCounts\"] >= lb)  & (df_infield[\"InFieldCitationCounts\"] < ub)].sort_values(\"InFieldCitationCounts\")[\"PaperId\"].to_list()\n",
    "        subclusters = clusters[clusters[\"PaperId\"].isin(paper_sublist)]\n",
    "        clusterdict = subclusters.set_index(\"PaperId\")[\"ClusterNum\"].to_dict()\n",
    "        if(len(subclusters) == 0):\n",
    "            continue\n",
    "        nmi_val = get_nmi_subset(clusterdict, paperfielddict)\n",
    "        subgran = calc_granularity_cludict(clusterdict)\n",
    "        res = param_list + [lb, ub, nmi_val, subgran, nmi_val/subgran]\n",
    "        now_count_list.append(res)\n",
    "    return now_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_process = 32\n",
    "filenames = sorted(glob.glob(\"./fastnvme01/Cluster_out/*.clu\"))\n",
    "count_result = []\n",
    "count_result.append([\"net_type\", \"field_name\", \"r_layer\", \"res\", \"citation_infield_lb\", \"citation_infield_ub\", \"nmi\", \"granularity\", \"nmi_per_gran\"])\n",
    "multip = 3\n",
    "pool = Pool(processes=no_process)\n",
    "sub_count_result = list(tqdm(pool.imap(nmi_calculate_citation_count, filenames), total=len(filenames), desc = \"QUANTILE\"))\n",
    "pool.close()\n",
    "count_list += list(itertools.chain(*sub_count_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(count_result[1:], columns=count_result[0])\n",
    "count_df.to_csv(\"./MAG_L2_Similarity/20201028_NMI_BY_CITATION_INFIELD.tsv\", index=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmi_calculate_citation_count_all(fname):\n",
    "    now_count_list = []\n",
    "    param_list = get_params_from_filename(fname)\n",
    "    L0FOSID = fos_l0_namedict[param_list[1]]   \n",
    "    clusters = pd.read_csv(fname, sep=\"\\t\", header=None, names=[\"PaperId\", \"ClusterNum\"])\n",
    "    max_len = int(math.log(df_all[(df_all[\"L0Field\"]==L0FOSID)][\"CitationCounts\"].max(), multip)) + 1\n",
    "    multip = 3\n",
    "    bound = [multip ** i for i in range(max_len)]    \n",
    "    for i in range(len(bound)-1):\n",
    "        lb = bound[i]\n",
    "        ub = bound[i+1]\n",
    "        paper_sublist = df_all[(df_all[\"L0Field\"]==L0FOSID) & (df_all[\"CitationCounts\"] >= lb)  & (df_all[\"CitationCounts\"] < ub)].sort_values(\"CitationCounts\")[\"PaperId\"].to_list()\n",
    "        subclusters = clusters[clusters[\"PaperId\"].isin(paper_sublist)]\n",
    "        clusterdict = subclusters.set_index(\"PaperId\")[\"ClusterNum\"].to_dict()\n",
    "        if(len(subclusters) == 0):\n",
    "            continue\n",
    "        nmi_val = get_nmi_subset(clusterdict, paperfielddict)\n",
    "        subgran = calc_granularity_cludict(clusterdict)\n",
    "        res = param_list + [lb, ub, nmi_val, subgran, nmi_val/subgran]\n",
    "        now_count_list.append(res)\n",
    "    return now_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_process = 32\n",
    "filenames = sorted(glob.glob(\"./fastnvme01/Cluster_out/*.clu\"))\n",
    "all_count_result = []\n",
    "all_count_result.append([\"net_type\", \"field_name\", \"r_layer\", \"res\", \"citation_infield_lb\", \"citation_infield_ub\", \"nmi\", \"granularity\", \"nmi_per_gran\"])\n",
    "\n",
    "pool = Pool(processes=no_process)\n",
    "sub_all_count_result = list(tqdm(pool.imap(nmi_calculate_quantiles, filenames), total=len(filenames), desc = \"QUANTILE\"))\n",
    "pool.close()\n",
    "all_count_result += list(itertools.chain(*sub_all_count_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_count_df = pd.DataFrame(all_count_result[1:], columns=all_count_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df.to_csv(\"./MAG_L2_Similarity/20201028_NMI_BY_CITATION_ALL.tsv\", index=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
